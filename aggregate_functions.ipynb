{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "249f30de-29bc-431b-a2f4-d538bbe9b802",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "spark = SparkSession.builder.appName('AGGREGATE_FUNCTIONS').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56a85ebb-bf74-4232-9336-2cc5108e5d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|James        |Sales     |3000  |\n",
      "|Michael      |Sales     |4600  |\n",
      "|Robert       |Sales     |4100  |\n",
      "|Maria        |Finance   |3000  |\n",
      "|James        |Sales     |3000  |\n",
      "|Scott        |Finance   |3300  |\n",
      "|Jen          |Finance   |3900  |\n",
      "|Jeff         |Marketing |3000  |\n",
      "|Kumar        |Marketing |2000  |\n",
      "|Saif         |Sales     |4100  |\n",
      "+-------------+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simpleData = [(\"James\", \"Sales\", 3000),\n",
    "    (\"Michael\", \"Sales\", 4600),\n",
    "    (\"Robert\", \"Sales\", 4100),\n",
    "    (\"Maria\", \"Finance\", 3000),\n",
    "    (\"James\", \"Sales\", 3000),\n",
    "    (\"Scott\", \"Finance\", 3300),\n",
    "    (\"Jen\", \"Finance\", 3900),\n",
    "    (\"Jeff\", \"Marketing\", 3000),\n",
    "    (\"Kumar\", \"Marketing\", 2000),\n",
    "    (\"Saif\", \"Sales\", 4100)\n",
    "  ]\n",
    "schema = [\"employee_name\", \"department\", \"salary\"]\n",
    "df = spark.createDataFrame(data=simpleData, schema = schema)\n",
    "\n",
    "df.show(truncate=False)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e936824-a26b-4029-9d54-7e65571b0261",
   "metadata": {},
   "source": [
    "### approx_count_distinct\n",
    "#### collect() - is used to retrieve all the elements of the DataFrame to the driver program\n",
    "#### collect()[0] -  accesses the first element of the array returned by collect()\n",
    "#### collect()[0][0] -  is used to extract the value of the first row and first column of the result \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ee14f6a-d81b-4752-b64f-c12f75ee6967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "approx_count_distinct: [Row(approx_count_distinct(department)=3)]\n",
      "approx_count_distinct: Row(approx_count_distinct(department)=3)\n",
      "approx_count_distinct: 3\n",
      "DataFrame[employee_name: string, department: string, salary: bigint]\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import approx_count_distinct\n",
    "\n",
    "print(\"approx_count_distinct: \" +str(df.select(approx_count_distinct(\"department\")).collect()))\n",
    "print(\"approx_count_distinct: \" +str(df.select(approx_count_distinct(\"department\")).collect()[0]))\n",
    "print(\"approx_count_distinct: \" +str(df.select(approx_count_distinct(\"department\")).collect()[0][0]))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416893d-3579-44f2-bb92-d8f7cb108507",
   "metadata": {},
   "source": [
    "### Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d829e43-4c51-44dd-8472-a99ec7e925ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg: 3400.0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "print(\"avg: \" + str(df.select(avg(\"salary\")).collect()[0][0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9393e0e6-3735-4059-9ce7-4d8210f88eb1",
   "metadata": {},
   "source": [
    "### collect_list - returns all values from an input column with duplicates.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c2ca4803-3f0a-4948-9573-887484e76456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------------------------+\n",
      "|collect_list(salary)                                        |\n",
      "+------------------------------------------------------------+\n",
      "|[3000, 4600, 4100, 3000, 3000, 3300, 3900, 3000, 2000, 4100]|\n",
      "+------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_list\n",
    "\n",
    "df.select(collect_list(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2f3a3d-a97f-4f12-aee7-09a595cf8f1c",
   "metadata": {},
   "source": [
    "### collect_set - returns all values from an input column with duplicate values eliminated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e541770e-3c5e-4701-840f-df6190606edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+\n",
      "|collect_set(salary)                 |\n",
      "+------------------------------------+\n",
      "|[4600, 3000, 3900, 4100, 3300, 2000]|\n",
      "+------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_set\n",
    "\n",
    "df.select(collect_set(\"salary\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd2b6ae-3301-42df-afd9-ece40ebcab08",
   "metadata": {},
   "source": [
    "### countDistinct - returns the number of distinct elements in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22308331-e2cd-4389-97ec-03c370eeda4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------+\n",
      "|count(DISTINCT department, salary)|\n",
      "+----------------------------------+\n",
      "|8                                 |\n",
      "+----------------------------------+\n",
      "\n",
      "Distinct Count of Department & Salary: 8\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "df2 = df.select(countDistinct(\"department\", \"salary\"))\n",
    "df2.show(truncate=False)\n",
    "print(\"Distinct Count of Department & Salary: \"+str(df2.collect()[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7edab9-bf43-449a-85ec-d20b79d04467",
   "metadata": {},
   "source": [
    "### count - returns number of elements in a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "912b810f-c952-4fb5-85fb-433bcd286f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 10\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count\n",
    "\n",
    "print(\"count: \"+str(df.select(count(\"salary\")).collect()[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcb0dfd-6199-4747-97b5-91e3b820da80",
   "metadata": {},
   "source": [
    "### grouping - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2edd2935-9f66-4505-a95d-66dffd290e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+------+\n",
      "|employee_name|department|salary|\n",
      "+-------------+----------+------+\n",
      "|        James|     Sales|  3000|\n",
      "|      Michael|     Sales|  4600|\n",
      "|       Robert|     Sales|  4100|\n",
      "|        Maria|   Finance|  3000|\n",
      "|        James|     Sales|  3000|\n",
      "|        Scott|   Finance|  3300|\n",
      "|          Jen|   Finance|  3900|\n",
      "|         Jeff| Marketing|  3000|\n",
      "|        Kumar| Marketing|  2000|\n",
      "|         Saif|     Sales|  4100|\n",
      "+-------------+----------+------+\n",
      "\n",
      "+----------+-------------+------------+---------------------+------------------------+\n",
      "|department|employee_name|total_salary|is_department_grouped|is_employee_name_grouped|\n",
      "+----------+-------------+------------+---------------------+------------------------+\n",
      "|     Sales|        James|        6000|                    0|                       0|\n",
      "|      NULL|         NULL|       34000|                    1|                       1|\n",
      "|     Sales|         NULL|       18800|                    0|                       1|\n",
      "|     Sales|      Michael|        4600|                    0|                       0|\n",
      "|     Sales|       Robert|        4100|                    0|                       0|\n",
      "|   Finance|         NULL|       10200|                    0|                       1|\n",
      "|   Finance|        Maria|        3000|                    0|                       0|\n",
      "|   Finance|        Scott|        3300|                    0|                       0|\n",
      "|   Finance|          Jen|        3900|                    0|                       0|\n",
      "| Marketing|         NULL|        5000|                    0|                       1|\n",
      "| Marketing|         Jeff|        3000|                    0|                       0|\n",
      "| Marketing|        Kumar|        2000|                    0|                       0|\n",
      "|     Sales|         Saif|        4100|                    0|                       0|\n",
      "+----------+-------------+------------+---------------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df.show()\n",
    "\n",
    "result_rollup = df.rollup(\"department\", \"employee_name\").agg(\n",
    "    F.sum(\"salary\").alias(\"total_salary\"),\n",
    "    F.grouping(\"department\").alias(\"is_department_grouped\"),\n",
    "    F.grouping(\"employee_name\").alias(\"is_employee_name_grouped\")\n",
    ")\n",
    "result_rollup.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
